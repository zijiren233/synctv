use anyhow::{Result, anyhow};
use redis::aio::ConnectionManager as RedisConnectionManager;
use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};
use tracing::{debug, info};

/// Heartbeat interval in seconds for publisher liveness.
/// The publisher manager sends a heartbeat every this many seconds.
pub const HEARTBEAT_INTERVAL_SECS: u64 = 60;

/// TTL multiplier: TTL = `HEARTBEAT_INTERVAL_SECS` * `TTL_MULTIPLIER`.
/// A multiplier of 5 means up to 4 consecutive missed heartbeats are tolerated
/// before the registry entry expires.
const TTL_MULTIPLIER: u64 = 5;

/// Publisher TTL in seconds, derived from heartbeat interval.
/// This is the Redis key expiration set on publisher entries.
pub const PUBLISHER_TTL_SECS: i64 = (HEARTBEAT_INTERVAL_SECS * TTL_MULTIPLIER) as i64;

/// Redis key for the global epoch counter used for fencing tokens.
/// Format: "stream:epoch:{room_id}:{media_id}"
/// Each publisher registration increments this counter atomically.
const EPOCH_KEY_PREFIX: &str = "stream:epoch";

// Compile-time safety check: TTL must be at least 3x the heartbeat interval
// to tolerate transient network issues.
const _: () = assert!(
    PUBLISHER_TTL_SECS as u64 >= HEARTBEAT_INTERVAL_SECS * 3,
    "PUBLISHER_TTL_SECS must be at least 3x HEARTBEAT_INTERVAL_SECS"
);

/// Publisher information stored in Redis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PublisherInfo {
    /// Node ID of the publisher
    pub node_id: String,
    /// gRPC address of the publisher node (e.g., "10.0.0.1:50051")
    /// Used by pull streams to connect to the publisher
    #[serde(default)]
    pub grpc_address: String,
    /// RTMP app name
    pub app_name: String,
    /// User ID of the publisher (for reverse-index lookups)
    #[serde(default)]
    pub user_id: String,
    /// When the stream started
    pub started_at: DateTime<Utc>,
    /// Fencing token (monotonically increasing epoch) for split-brain prevention
    /// When a new publisher registers (after TTL expiry), this counter increments.
    /// Pull streams must validate their token matches to prevent stale connections.
    #[serde(default)]
    pub epoch: u64,
}

/// Stream registry for tracking active publishers
#[derive(Clone)]
pub struct StreamRegistry {
    redis: RedisConnectionManager,
}

impl StreamRegistry {
    /// Create a new stream registry
    #[must_use] 
    pub const fn new(redis: RedisConnectionManager) -> Self {
        Self { redis }
    }

    /// Register a publisher for a media in a room (atomic operation)
    /// Returns true if registered successfully, false if already exists
    ///
    /// Delegates to the atomic Lua-based `try_register_publisher_with_user()`
    /// to prevent epoch inflation on failed registration attempts.
    pub async fn register_publisher(
        &mut self,
        room_id: &str,
        media_id: &str,
        node_id: &str,
        _app_name: &str,
    ) -> anyhow::Result<bool> {
        self.try_register_publisher_with_user(room_id, media_id, node_id, "").await
    }

    /// Try to register as publisher (simplified version for `PublisherManager`)
    /// Returns true if registered successfully, false if already exists
    pub async fn try_register_publisher(
        &self,
        room_id: &str,
        media_id: &str,
        node_id: &str,
    ) -> anyhow::Result<bool> {
        self.try_register_publisher_with_user(room_id, media_id, node_id, "").await
    }

    /// Try to register as publisher with `user_id`
    /// Returns true if registered successfully, false if already exists
    ///
    /// FIXED: P0.5 - Uses atomic Lua script to prevent epoch race condition
    /// The script ensures INCR + HSETNX are atomic - if HSETNX fails, epoch is rolled back
    pub async fn try_register_publisher_with_user(
        &self,
        room_id: &str,
        media_id: &str,
        node_id: &str,
        user_id: &str,
    ) -> anyhow::Result<bool> {
        let key = format!("stream:publisher:{room_id}:{media_id}");
        let epoch_key = format!("{EPOCH_KEY_PREFIX}:{room_id}:{media_id}");
        let mut conn = self.redis.clone();

        // Create PublisherInfo template (epoch will be filled by Lua script)
        let info = PublisherInfo {
            node_id: node_id.to_string(),
            grpc_address: String::new(),
            app_name: "live".to_string(),
            user_id: user_id.to_string(),
            started_at: Utc::now(),
            epoch: 0, // Placeholder, will be replaced by actual epoch in Lua script
        };
        let info_json = serde_json::to_string(&info)?;

        // Atomic Lua script to prevent epoch race condition
        // Returns: {registered (1 or 0), epoch}
        // If HSETNX fails, epoch is decremented (rolled back)
        let lua_script = r#"
            local epoch_key = KEYS[1]
            local hash_key = KEYS[2]
            local info_json_template = ARGV[1]
            local ttl = tonumber(ARGV[2])
            local user_key = ARGV[3]
            local user_member = ARGV[4]

            -- Atomically increment epoch
            local epoch = redis.call('INCR', epoch_key)

            -- Replace placeholder epoch in JSON (assumes epoch:0 pattern)
            local info_json = string.gsub(info_json_template, '"epoch":0', '"epoch":' .. epoch)

            -- Try to register (HSETNX returns 1 if set, 0 if exists)
            local registered = redis.call('HSETNX', hash_key, 'publisher', info_json)

            if registered == 0 then
                -- Registration failed, rollback epoch
                redis.call('DECR', epoch_key)
                return {0, epoch - 1}
            end

            -- Registration successful, set TTL
            redis.call('EXPIRE', hash_key, ttl)

            -- Add to user reverse index if provided
            if user_key ~= '' then
                redis.call('SADD', user_key, user_member)
                redis.call('EXPIRE', user_key, ttl)
            end

            return {1, epoch}
        "#;

        let user_key = if !user_id.is_empty() {
            format!("stream:user_publishers:{user_id}")
        } else {
            String::new()
        };
        let user_member = format!("{room_id}:{media_id}");

        let result: Vec<i64> = redis::Script::new(lua_script)
            .key(&epoch_key)
            .key(&key)
            .arg(&info_json)
            .arg(PUBLISHER_TTL_SECS)
            .arg(&user_key)
            .arg(&user_member)
            .invoke_async(&mut conn)
            .await
            .map_err(|e| anyhow!("Lua script execution failed: {}", e))?;

        let registered = result[0] == 1;
        let actual_epoch = result[1] as u64;

        if registered {
            info!(
                "Publisher registered atomically: room={}, media={}, node={}, epoch={}",
                room_id, media_id, node_id, actual_epoch
            );
        } else {
            debug!(
                "Publisher already exists: room={}, media={}, attempted_epoch={}",
                room_id, media_id, actual_epoch
            );
        }

        // Note: User reverse index (user_publishers) is already handled atomically
        // by the Lua script above, no additional Redis calls needed

        Ok(registered)
    }

    /// Refresh TTL for a publisher (called by heartbeat)
    pub async fn refresh_publisher_ttl(&self, room_id: &str, media_id: &str) -> Result<()> {
        self.refresh_publisher_ttl_with_user(room_id, media_id, "").await
    }

    /// Refresh TTL for a publisher and its user reverse-index (called by heartbeat)
    pub async fn refresh_publisher_ttl_with_user(&self, room_id: &str, media_id: &str, user_id: &str) -> Result<()> {
        let key = format!("stream:publisher:{room_id}:{media_id}");
        let mut conn = self.redis.clone();

        // Refresh publisher key TTL (derived from HEARTBEAT_INTERVAL_SECS * TTL_MULTIPLIER)
        let _: () = redis::cmd("EXPIRE")
            .arg(&key)
            .arg(PUBLISHER_TTL_SECS)
            .query_async(&mut conn)
            .await
            .map_err(|e| anyhow!(e.to_string()))?;

        // Also refresh user reverse-index TTL if user_id is provided
        if !user_id.is_empty() {
            let user_key = format!("stream:user_publishers:{user_id}");
            let _: () = redis::cmd("EXPIRE")
                .arg(&user_key)
                .arg(PUBLISHER_TTL_SECS)
                .query_async(&mut conn)
                .await
                .map_err(|e| anyhow!(e.to_string()))?;
        }

        Ok(())
    }

    /// Unregister a publisher
    ///
    /// Delegates to `unregister_publisher_immut` which correctly cleans up
    /// both the publisher entry and the user reverse index.
    pub async fn unregister_publisher(&mut self, room_id: &str, media_id: &str) -> Result<()> {
        self.unregister_publisher_immut(room_id, media_id).await
    }

    /// Unregister a publisher (non-mut version for `PublisherManager`)
    pub async fn unregister_publisher_immut(&self, room_id: &str, media_id: &str) -> Result<()> {
        self.unregister_publisher_with_epoch(room_id, media_id, None).await
    }

    /// Epoch-validated unregister: only deletes if the stored epoch matches the expected epoch.
    /// If `expected_epoch` is None, deletes unconditionally (backwards compatible).
    ///
    /// This prevents a race where publisher A dies, publisher B registers, then
    /// publisher A's delayed cleanup incorrectly removes publisher B's entry.
    pub async fn unregister_publisher_with_epoch(
        &self,
        room_id: &str,
        media_id: &str,
        expected_epoch: Option<u64>,
    ) -> Result<()> {
        let key = format!("stream:publisher:{room_id}:{media_id}");
        let mut conn = self.redis.clone();

        // Atomic Lua script: check epoch (if provided), delete publisher, clean up user index
        let lua_script = r#"
            local hash_key = KEYS[1]
            local check_epoch = tonumber(ARGV[1])

            -- Get current publisher info
            local info_json = redis.call('HGET', hash_key, 'publisher')
            if not info_json then
                return {0, ''}
            end

            -- If epoch check is requested, validate before deleting
            if check_epoch >= 0 then
                -- Extract epoch from JSON using pattern match
                local stored_epoch = string.match(info_json, '"epoch":(%d+)')
                if stored_epoch and tonumber(stored_epoch) ~= check_epoch then
                    -- Epoch mismatch: a newer publisher registered, do NOT delete
                    return {-1, ''}
                end
            end

            -- Extract user_id for reverse-index cleanup
            local user_id = string.match(info_json, '"user_id":"([^"]*)"')

            -- Delete the publisher entry
            redis.call('HDEL', hash_key, 'publisher')

            return {1, user_id or ''}
        "#;

        // Use -1 to mean "no epoch check" (unconditional delete)
        let epoch_arg: i64 = match expected_epoch {
            Some(e) => e as i64,
            None => -1,
        };

        let result: Vec<redis::Value> = redis::Script::new(lua_script)
            .key(&key)
            .arg(epoch_arg)
            .invoke_async(&mut conn)
            .await
            .map_err(|e| anyhow!("Unregister Lua script failed: {e}"))?;

        // Parse result: [status, user_id]
        let status = match &result[0] {
            redis::Value::Int(v) => *v,
            _ => 0,
        };
        let user_id = match &result[1] {
            redis::Value::BulkString(s) => String::from_utf8_lossy(s).to_string(),
            redis::Value::SimpleString(s) => s.clone(),
            _ => String::new(),
        };

        if status == -1 {
            info!(
                "Skipped unregister for room={}, media={}: epoch mismatch (newer publisher exists)",
                room_id, media_id
            );
            return Ok(());
        }

        // Clean up user reverse index if user_id was present
        if status == 1 && !user_id.is_empty() {
            let user_key = format!("stream:user_publishers:{user_id}");
            let member = format!("{room_id}:{media_id}");
            let _: () = redis::cmd("SREM")
                .arg(&user_key)
                .arg(&member)
                .query_async(&mut conn)
                .await
                .map_err(|e| anyhow!(e.to_string()))?;
        }

        Ok(())
    }

    /// Get all active publishers for a user (via reverse index)
    /// Returns list of (`room_id`, `media_id`) pairs
    pub async fn get_user_publishers(&self, user_id: &str) -> Result<Vec<(String, String)>> {
        let user_key = format!("stream:user_publishers:{user_id}");
        let mut conn = self.redis.clone();

        let members: Vec<String> = redis::cmd("SMEMBERS")
            .arg(&user_key)
            .query_async(&mut conn)
            .await
            .map_err(|e| anyhow!(e.to_string()))?;

        Ok(members
            .into_iter()
            .filter_map(|m| {
                m.split_once(':')
                    .map(|(r, m)| (r.to_string(), m.to_string()))
            })
            .collect())
    }

    /// Remove all publisher entries for a user (via reverse index)
    pub async fn unregister_all_user_publishers(&self, user_id: &str) -> Result<()> {
        let publishers = self.get_user_publishers(user_id).await?;
        for (room_id, media_id) in publishers {
            self.unregister_publisher_immut(&room_id, &media_id).await?;
        }
        Ok(())
    }

    /// Get publisher info for a media in a room
    pub async fn get_publisher(&mut self, room_id: &str, media_id: &str) -> Result<Option<PublisherInfo>> {
        self.get_publisher_immut(room_id, media_id).await
    }

    /// Get publisher info for a media in a room (immutable version)
    pub async fn get_publisher_immut(&self, room_id: &str, media_id: &str) -> Result<Option<PublisherInfo>> {
        let key = format!("stream:publisher:{room_id}:{media_id}");
        let mut conn = self.redis.clone();
        let info_json: Option<String> = redis::cmd("HGET")
            .arg(&key)
            .arg("publisher")
            .query_async(&mut conn)
            .await
            .map_err(|e| anyhow!(e.to_string()))?;

        match info_json {
            Some(json) => {
                let info: PublisherInfo = serde_json::from_str(&json)?;
                Ok(Some(info))
            }
            None => Ok(None),
        }
    }


    /// Check if a stream is active (has a publisher)
    pub async fn is_stream_active(&mut self, room_id: &str, media_id: &str) -> anyhow::Result<bool> {
        self.is_stream_active_immut(room_id, media_id).await
    }

    /// Check if a stream is active (immutable version)
    pub async fn is_stream_active_immut(&self, room_id: &str, media_id: &str) -> anyhow::Result<bool> {
        let key = format!("stream:publisher:{room_id}:{media_id}");
        let mut conn = self.redis.clone();
        let exists: bool = redis::cmd("HEXISTS")
            .arg(&key)
            .arg("publisher")
            .query_async(&mut conn)
            .await
            .map_err(|e| anyhow!(e.to_string()))?;
        Ok(exists)
    }

    /// List all active streams (returns tuples of (`room_id`, `media_id`))
    pub async fn list_active_streams(&mut self) -> Result<Vec<(String, String)>> {
        self.list_active_streams_immut().await
    }

    /// List all active streams (immutable version)
    ///
    /// Uses SCAN instead of KEYS to avoid blocking Redis on large datasets.
    /// SCAN iterates through keys incrementally without blocking the server.
    pub async fn list_active_streams_immut(&self) -> Result<Vec<(String, String)>> {
        let mut conn = self.redis.clone();
        let mut streams = Vec::new();
        let mut cursor: u64 = 0;

        loop {
            // SCAN returns (new_cursor, keys)
            let (new_cursor, keys): (u64, Vec<String>) = redis::cmd("SCAN")
                .arg(cursor)
                .arg("MATCH")
                .arg("stream:publisher:*")
                .arg("COUNT")
                .arg(100) // Scan 100 keys per iteration for better performance
                .query_async(&mut conn)
                .await
                .map_err(|e| anyhow!(e.to_string()))?;

            // Parse keys into (room_id, media_id) tuples
            for k in keys {
                if let Some(s) = k.strip_prefix("stream:publisher:") {
                    let parts: Vec<&str> = s.split(':').collect();
                    if parts.len() == 2 {
                        streams.push((parts[0].to_string(), parts[1].to_string()));
                    }
                }
            }

            cursor = new_cursor;
            // cursor returns to 0 when scan is complete
            if cursor == 0 {
                break;
            }
        }

        Ok(streams)
    }

    /// Validate that the given epoch matches the current publisher's epoch.
    /// Returns Ok(true) if the epoch is valid, Ok(false) if stale/invalid.
    /// Used by pull streams to detect split-brain scenarios.
    pub async fn validate_epoch(&self, room_id: &str, media_id: &str, epoch: u64) -> Result<bool> {
        let key = format!("stream:publisher:{room_id}:{media_id}");
        let mut conn = self.redis.clone();

        // Get current publisher info
        let info_json: Option<String> = redis::cmd("HGET")
            .arg(&key)
            .arg("publisher")
            .query_async(&mut conn)
            .await
            .map_err(|e| anyhow!(e.to_string()))?;

        match info_json {
            Some(json) => {
                let info: PublisherInfo = serde_json::from_str(&json)?;
                // Epoch is valid if it matches the current publisher's epoch
                Ok(info.epoch == epoch)
            }
            None => {
                // Publisher no longer exists, epoch is invalid
                Ok(false)
            }
        }
    }

    /// Get the current epoch for a stream without publisher info.
    /// Returns None if no publisher exists.
    pub async fn get_current_epoch(&self, room_id: &str, media_id: &str) -> Result<Option<u64>> {
        let publisher = self.get_publisher_immut(room_id, media_id).await?;
        Ok(publisher.map(|p| p.epoch))
    }

    /// Clean up all publisher registrations for a specific node.
    /// Used when a node restarts to remove stale entries from Redis.
    ///
    /// This uses SCAN to iterate through all publisher keys and removes
    /// those belonging to the specified node_id.
    pub async fn cleanup_all_publishers_for_node(&self, node_id: &str) -> Result<()> {
        let mut conn = self.redis.clone();
        let mut cursor: u64 = 0;

        loop {
            // SCAN for publisher keys
            let (new_cursor, keys): (u64, Vec<String>) = redis::cmd("SCAN")
                .arg(cursor)
                .arg("MATCH")
                .arg("stream:publisher:*")
                .arg("COUNT")
                .arg(100)
                .query_async(&mut conn)
                .await
                .map_err(|e| anyhow!(e.to_string()))?;

            // Check each key and remove if it belongs to the node
            for key in keys {
                // Extract room_id and media_id from key: "stream:publisher:{room_id}:{media_id}"
                let key_suffix = match key.strip_prefix("stream:publisher:") {
                    Some(s) => s,
                    None => continue,
                };
                let (room_id, media_id) = match key_suffix.split_once(':') {
                    Some((r, m)) => (r.to_string(), m.to_string()),
                    None => continue,
                };

                // Get publisher info
                let info_json: Option<String> = redis::cmd("HGET")
                    .arg(&key)
                    .arg("publisher")
                    .query_async(&mut conn)
                    .await
                    .map_err(|e| anyhow!(e.to_string()))?;

                if let Some(json) = info_json {
                    if let Ok(info) = serde_json::from_str::<PublisherInfo>(&json) {
                        if info.node_id == node_id {
                            // Remove the publisher entry
                            let _: () = redis::cmd("HDEL")
                                .arg(&key)
                                .arg("publisher")
                                .query_async(&mut conn)
                                .await
                                .map_err(|e| anyhow!(e.to_string()))?;

                            // Also clean up user reverse index if present
                            if !info.user_id.is_empty() {
                                let user_key = format!("stream:user_publishers:{}", info.user_id);
                                let member = format!("{}:{}", room_id, media_id);
                                let _: () = redis::cmd("SREM")
                                    .arg(&user_key)
                                    .arg(&member)
                                    .query_async(&mut conn)
                                    .await
                                    .map_err(|e| anyhow!(e.to_string()))?;
                            }

                            info!(
                                "Cleaned up stale publisher entry for node {} (room: {}, media: {})",
                                node_id,
                                room_id,
                                media_id
                            );
                        }
                    }
                }
            }

            cursor = new_cursor;
            if cursor == 0 {
                break;
            }
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    #[ignore = "Requires Redis server"]
    async fn test_register_publisher_success() {
        let redis_client = redis::Client::open("redis://localhost:6379").unwrap();
        let redis = RedisConnectionManager::new(redis_client).await.unwrap();
        let mut registry = StreamRegistry::new(redis);

        // First registration should succeed
        let registered = registry
            .register_publisher("room123", "media456", "node1", "live")
            .await
            .unwrap();
        assert!(registered);

        // Verify publisher exists
        let publisher = registry.get_publisher("room123", "media456").await.unwrap();
        assert!(publisher.is_some());

        let pub_info = publisher.unwrap();
        assert_eq!(pub_info.node_id, "node1");
        assert_eq!(pub_info.app_name, "live");

        // Cleanup
        registry.unregister_publisher("room123", "media456").await.unwrap();
    }

    #[tokio::test]
    #[ignore = "Requires Redis server"]
    async fn test_register_publisher_duplicate() {
        let redis_client = redis::Client::open("redis://localhost:6379").unwrap();
        let redis = RedisConnectionManager::new(redis_client).await.unwrap();
        let mut registry = StreamRegistry::new(redis);

        // First registration should succeed
        let registered = registry
            .register_publisher("room123", "media456", "node1", "live")
            .await
            .unwrap();
        assert!(registered);

        // Second registration should fail (already exists)
        let registered = registry
            .register_publisher("room123", "media456", "node2", "live")
            .await
            .unwrap();
        assert!(!registered);

        // Cleanup
        registry.unregister_publisher("room123", "media456").await.unwrap();
    }

    #[tokio::test]
    #[ignore = "Requires Redis server"]
    async fn test_try_register_publisher() {
        let redis_client = redis::Client::open("redis://localhost:6379").unwrap();
        let redis = RedisConnectionManager::new(redis_client).await.unwrap();
        let mut registry = StreamRegistry::new(redis);

        // First try_register should succeed
        let result = registry.try_register_publisher("room123", "media456", "node1").await.unwrap();
        assert!(result);

        // Second try_register should return false (already exists)
        let result = registry.try_register_publisher("room123", "media456", "node2").await.unwrap();
        assert!(!result);

        // Cleanup
        registry.unregister_publisher("room123", "media456").await.unwrap();
    }

    #[tokio::test]
    #[ignore = "Requires Redis server"]
    async fn test_unregister_publisher() {
        let redis_client = redis::Client::open("redis://localhost:6379").unwrap();
        let redis = RedisConnectionManager::new(redis_client).await.unwrap();
        let mut registry = StreamRegistry::new(redis);

        // Register publisher
        registry
            .register_publisher("room123", "media456", "node1", "live")
            .await
            .unwrap();

        // Verify exists
        assert!(registry.is_stream_active("room123", "media456").await.unwrap());

        // Unregister
        registry.unregister_publisher("room123", "media456").await.unwrap();

        // Verify removed
        assert!(!registry.is_stream_active("room123", "media456").await.unwrap());
    }

    #[tokio::test]
    #[ignore = "Requires Redis server"]
    async fn test_get_publisher_not_found() {
        let redis_client = redis::Client::open("redis://localhost:6379").unwrap();
        let redis = RedisConnectionManager::new(redis_client).await.unwrap();
        let mut registry = StreamRegistry::new(redis);

        // Non-existent publisher should return None
        let result = registry.get_publisher("nonexistent", "media").await.unwrap();
        assert!(result.is_none());
    }

    #[tokio::test]
    #[ignore = "Requires Redis server"]
    async fn test_list_active_streams() {
        let redis_client = redis::Client::open("redis://localhost:6379").unwrap();
        let redis = RedisConnectionManager::new(redis_client).await.unwrap();
        let mut registry = StreamRegistry::new(redis);

        // Register multiple publishers
        registry
            .register_publisher("room1", "media1", "node1", "live")
            .await
            .unwrap();
        registry
            .register_publisher("room2", "media2", "node1", "live")
            .await
            .unwrap();

        // List active streams
        let streams = registry.list_active_streams().await.unwrap();
        assert_eq!(streams.len(), 2);
        assert!(streams.contains(&(String::from("room1"), String::from("media1"))));
        assert!(streams.contains(&(String::from("room2"), String::from("media2"))));

        // Cleanup
        registry.unregister_publisher("room1", "media1").await.unwrap();
        registry.unregister_publisher("room2", "media2").await.unwrap();
    }

    #[tokio::test]
    #[ignore = "Requires Redis server"]
    async fn test_publisher_info_serialization() {
        let redis_client = redis::Client::open("redis://localhost:6379").unwrap();
        let redis = RedisConnectionManager::new(redis_client).await.unwrap();
        let mut registry = StreamRegistry::new(redis);

        // Register publisher
        registry
            .register_publisher("room123", "media456", "node1", "live")
            .await
            .unwrap();

        // Get publisher and verify serialization/deserialization
        let publisher = registry.get_publisher("room123", "media456").await.unwrap().unwrap();

        assert_eq!(publisher.node_id, "node1");
        assert_eq!(publisher.app_name, "live");
        assert!(publisher.started_at <= chrono::Utc::now());

        // Cleanup
        registry.unregister_publisher("room123", "media456").await.unwrap();
    }
}
