//! Media repository for database operations
//!
//! Design reference: /Volumes/workspace/rust/design/04-数据库设计.md §2.4.2

use sqlx::{postgres::PgRow, PgPool, Row};

use crate::{
    models::{Media, MediaId, PlaylistId, RoomId},
    Result,
};

/// Media repository for database operations
#[derive(Clone)]
pub struct MediaRepository {
    pool: PgPool,
}

impl MediaRepository {
    #[must_use]
    pub const fn new(pool: PgPool) -> Self {
        Self { pool }
    }

    /// Get a reference to the connection pool
    #[must_use]
    pub const fn pool(&self) -> &PgPool {
        &self.pool
    }

    /// Add media to playlist
    pub async fn create(&self, media: &Media) -> Result<Media> {
        let source_config_json = serde_json::to_value(&media.source_config)?;

        let row = sqlx::query(
            r"
            INSERT INTO media (id, playlist_id, room_id, creator_id, name, position,
                              source_provider, source_config, provider_instance_name, added_at)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
             RETURNING id, playlist_id, room_id, creator_id, name, position,
                       source_provider, source_config, provider_instance_name,
                       added_at, deleted_at
            "
        )
        .bind(media.id.as_str())
        .bind(media.playlist_id.as_str())
        .bind(media.room_id.as_str())
        .bind(media.creator_id.as_str())
        .bind(&media.name)
        .bind(media.position)
        .bind(media.source_provider.as_str())
        .bind(&source_config_json)
        .bind(&media.provider_instance_name)
        .bind(media.added_at)
        .fetch_one(&self.pool)
        .await?;

        self.row_to_media(row)
    }

    /// Batch insert media items
    pub async fn create_batch(&self, items: &[Media]) -> Result<Vec<Media>> {
        let mut tx = self.pool.begin().await?;
        let results = self.create_batch_with_executor(items, &mut *tx).await?;
        tx.commit().await?;
        Ok(results)
    }

    /// Batch insert media items using a provided executor (for transaction support)
    pub async fn create_batch_with_executor<'e, E>(&self, items: &[Media], executor: E) -> Result<Vec<Media>>
    where
        E: sqlx::Executor<'e, Database = sqlx::Postgres>,
    {
        if items.is_empty() {
            return Ok(Vec::new());
        }

        // For executor-based usage, we need to execute all queries on the same executor.
        // Since sqlx::Executor is consumed on use, we need to use a reference.
        // The caller should pass &mut *tx where tx is a Transaction.
        let mut results = Vec::with_capacity(items.len());

        // Build a single batch insert query for efficiency
        let mut query_builder = String::from(
            "INSERT INTO media (id, playlist_id, room_id, creator_id, name, position,
                               source_provider, source_config, provider_instance_name, added_at)
             VALUES "
        );
        let mut binds = Vec::new();
        for (i, item) in items.iter().enumerate() {
            if i > 0 {
                query_builder.push_str(", ");
            }
            let base = i * 10;
            query_builder.push_str(&format!(
                "(${}, ${}, ${}, ${}, ${}, ${}, ${}, ${}, ${}, ${})",
                base + 1, base + 2, base + 3, base + 4, base + 5,
                base + 6, base + 7, base + 8, base + 9, base + 10
            ));
            binds.push(serde_json::to_value(&item.source_config)?);
        }
        query_builder.push_str(
            " RETURNING id, playlist_id, room_id, creator_id, name, position,
                       source_provider, source_config, provider_instance_name,
                       added_at, deleted_at"
        );

        let mut query = sqlx::query(&query_builder);
        for (i, item) in items.iter().enumerate() {
            query = query
                .bind(item.id.as_str())
                .bind(item.playlist_id.as_str())
                .bind(item.room_id.as_str())
                .bind(item.creator_id.as_str())
                .bind(&item.name)
                .bind(item.position)
                .bind(item.source_provider.as_str())
                .bind(&binds[i])
                .bind(&item.provider_instance_name)
                .bind(item.added_at);
        }

        let rows = query.fetch_all(executor).await?;
        for row in rows {
            results.push(self.row_to_media(row)?);
        }

        Ok(results)
    }

    /// Update media
    pub async fn update(&self, media: &Media) -> Result<Media> {
        let source_config_json = serde_json::to_value(&media.source_config)?;

        let row = sqlx::query(
            r"
            UPDATE media
            SET name = $2, position = $3, source_config = $4,
                provider_instance_name = $5
             WHERE id = $1 AND deleted_at IS NULL
             RETURNING id, playlist_id, room_id, creator_id, name, position,
                       source_provider, source_config, provider_instance_name,
                       added_at, deleted_at
            "
        )
        .bind(media.id.as_str())
        .bind(&media.name)
        .bind(media.position)
        .bind(&source_config_json)
        .bind(&media.provider_instance_name)
        .fetch_one(&self.pool)
        .await?;

        self.row_to_media(row)
    }

    /// Get media by ID
    pub async fn get_by_id(&self, media_id: &MediaId) -> Result<Option<Media>> {
        let row = sqlx::query(
            r"
            SELECT id, playlist_id, room_id, creator_id, name, position,
                   source_provider, source_config, provider_instance_name,
                   added_at, deleted_at
             FROM media
             WHERE id = $1 AND deleted_at IS NULL
            "
        )
        .bind(media_id.as_str())
        .fetch_optional(&self.pool)
        .await?;

        match row {
            Some(row) => Ok(Some(self.row_to_media(row)?)),
            None => Ok(None),
        }
    }

    /// Get multiple media items by IDs in a single query
    pub async fn get_by_ids(&self, media_ids: &[MediaId]) -> Result<Vec<Media>> {
        self.get_by_ids_with_executor(media_ids, &self.pool).await
    }

    /// Get multiple media items by IDs using a specific executor (for transaction support)
    pub async fn get_by_ids_with_executor<'e, E>(&self, media_ids: &[MediaId], executor: E) -> Result<Vec<Media>>
    where
        E: sqlx::Executor<'e, Database = sqlx::Postgres>,
    {
        if media_ids.is_empty() {
            return Ok(Vec::new());
        }

        let id_strs: Vec<&str> = media_ids.iter().map(super::super::models::id::MediaId::as_str).collect();
        let rows = sqlx::query(
            r"
            SELECT id, playlist_id, room_id, creator_id, name, position,
                   source_provider, source_config, provider_instance_name,
                   added_at, deleted_at
             FROM media
             WHERE id = ANY($1) AND deleted_at IS NULL
            "
        )
        .bind(&id_strs)
        .fetch_all(executor)
        .await?;

        rows.into_iter().map(|row| self.row_to_media(row)).collect()
    }

    /// Get playlist for a room (all media in room's root playlist and sub-playlists)
    pub async fn get_playlist(&self, room_id: &RoomId) -> Result<Vec<Media>> {
        let rows = sqlx::query(
            r"
            SELECT id, playlist_id, room_id, creator_id, name, position,
                   source_provider, source_config, provider_instance_name,
                   added_at, deleted_at
             FROM media
             WHERE room_id = $1 AND deleted_at IS NULL
             ORDER BY playlist_id, position ASC
            "
        )
        .bind(room_id.as_str())
        .fetch_all(&self.pool)
        .await?;

        rows.into_iter().map(|row| self.row_to_media(row)).collect()
    }

    /// Get media in a specific playlist
    pub async fn get_by_playlist(&self, playlist_id: &PlaylistId) -> Result<Vec<Media>> {
        let rows = sqlx::query(
            r"
            SELECT id, playlist_id, room_id, creator_id, name, position,
                   source_provider, source_config, provider_instance_name,
                   added_at, deleted_at
             FROM media
             WHERE playlist_id = $1 AND deleted_at IS NULL
             ORDER BY position ASC
            "
        )
        .bind(playlist_id.as_str())
        .fetch_all(&self.pool)
        .await?;

        rows.into_iter().map(|row| self.row_to_media(row)).collect()
    }

    /// Get paginated playlist
    pub async fn get_playlist_paginated(
        &self,
        playlist_id: &PlaylistId,
        page: i32,
        page_size: i32,
    ) -> Result<(Vec<Media>, i64)> {
        let offset = (page - 1) * page_size;

        // Get total count
        let total: i64 = sqlx::query_scalar(
            r"
            SELECT COUNT(*) FROM media WHERE playlist_id = $1 AND deleted_at IS NULL
            "
        )
        .bind(playlist_id.as_str())
        .fetch_one(&self.pool)
        .await?;

        // Get paginated results
        let rows = sqlx::query(
            r"
            SELECT id, playlist_id, room_id, creator_id, name, position,
                   source_provider, source_config, provider_instance_name,
                   added_at, deleted_at
             FROM media
             WHERE playlist_id = $1 AND deleted_at IS NULL
             ORDER BY position ASC
             LIMIT $2 OFFSET $3
            "
        )
        .bind(playlist_id.as_str())
        .bind(i64::from(page_size))
        .bind(i64::from(offset))
        .fetch_all(&self.pool)
        .await?;

        let items: Vec<Media> = rows.into_iter().map(|row| self.row_to_media(row)).collect::<Result<Vec<Media>>>()?;

        Ok((items, total))
    }

    /// Delete media from playlist (soft delete)
    pub async fn delete(&self, media_id: &MediaId) -> Result<bool> {
        let result = sqlx::query(
            r"
            UPDATE media
             SET deleted_at = $2
             WHERE id = $1 AND deleted_at IS NULL
            "
        )
        .bind(media_id.as_str())
        .bind(chrono::Utc::now())
        .execute(&self.pool)
        .await?;

        Ok(result.rows_affected() > 0)
    }

    /// Delete all media in a playlist
    pub async fn delete_by_playlist(&self, playlist_id: &PlaylistId) -> Result<usize> {
        let result = sqlx::query(
            r"
            UPDATE media
             SET deleted_at = $2
             WHERE playlist_id = $1 AND deleted_at IS NULL
            "
        )
        .bind(playlist_id.as_str())
        .bind(chrono::Utc::now())
        .execute(&self.pool)
        .await?;

        Ok(result.rows_affected() as usize)
    }

    /// Bulk delete media items by IDs
    pub async fn delete_batch(&self, media_ids: &[MediaId]) -> Result<usize> {
        self.delete_batch_with_executor(media_ids, &self.pool).await
    }

    /// Bulk delete media items by IDs using a specific executor (for transaction support)
    pub async fn delete_batch_with_executor<'e, E>(&self, media_ids: &[MediaId], executor: E) -> Result<usize>
    where
        E: sqlx::Executor<'e, Database = sqlx::Postgres>,
    {
        if media_ids.is_empty() {
            return Ok(0);
        }

        let id_strs: Vec<&str> = media_ids.iter().map(super::super::models::id::MediaId::as_str).collect();
        let now = chrono::Utc::now();

        let result = sqlx::query(
            r"
            UPDATE media
             SET deleted_at = $2
             WHERE id = ANY($1) AND deleted_at IS NULL
            "
        )
        .bind(&id_strs)
        .bind(now)
        .execute(executor)
        .await?;

        Ok(result.rows_affected() as usize)
    }

    /// Swap positions of two media
    pub async fn swap_positions(&self, media_id1: &MediaId, media_id2: &MediaId) -> Result<()> {
        let mut tx = self.pool.begin().await?;
        self.swap_positions_with_tx(media_id1, media_id2, &mut tx).await?;
        tx.commit().await?;
        Ok(())
    }

    /// Swap positions of two media using a provided transaction
    pub async fn swap_positions_with_tx(
        &self,
        media_id1: &MediaId,
        media_id2: &MediaId,
        tx: &mut sqlx::Transaction<'_, sqlx::Postgres>,
    ) -> Result<()> {
        let pos1: i32 = sqlx::query_scalar("SELECT position FROM media WHERE id = $1 FOR UPDATE")
            .bind(media_id1.as_str())
            .fetch_one(&mut **tx)
            .await?;

        let pos2: i32 = sqlx::query_scalar("SELECT position FROM media WHERE id = $1 FOR UPDATE")
            .bind(media_id2.as_str())
            .fetch_one(&mut **tx)
            .await?;

        sqlx::query("UPDATE media SET position = $2 WHERE id = $1")
            .bind(media_id1.as_str())
            .bind(pos2)
            .execute(&mut **tx)
            .await?;

        sqlx::query("UPDATE media SET position = $2 WHERE id = $1")
            .bind(media_id2.as_str())
            .bind(pos1)
            .execute(&mut **tx)
            .await?;

        Ok(())
    }

    /// Bulk reorder media items with new positions
    /// Takes a list of (`media_id`, `new_position`) tuples and updates them in a transaction.
    /// Uses FOR UPDATE locks to prevent concurrent reordering race conditions.
    pub async fn reorder_batch(&self, updates: &[(MediaId, i32)]) -> Result<()> {
        let mut tx = self.pool.begin().await?;
        self.reorder_batch_with_tx(updates, &mut tx).await?;
        tx.commit().await?;
        Ok(())
    }

    /// Bulk reorder media items using a provided transaction
    pub async fn reorder_batch_with_tx(
        &self,
        updates: &[(MediaId, i32)],
        tx: &mut sqlx::Transaction<'_, sqlx::Postgres>,
    ) -> Result<()> {
        if updates.is_empty() {
            return Ok(());
        }

        // Lock all affected rows first to prevent concurrent modification
        for (media_id, _) in updates {
            sqlx::query("SELECT id FROM media WHERE id = $1 AND deleted_at IS NULL FOR UPDATE")
                .bind(media_id.as_str())
                .fetch_optional(&mut **tx)
                .await?;
        }

        // Now update positions within the lock scope
        for (media_id, new_position) in updates {
            sqlx::query("UPDATE media SET position = $2 WHERE id = $1 AND deleted_at IS NULL")
                .bind(media_id.as_str())
                .bind(new_position)
                .execute(&mut **tx)
                .await?;
        }

        Ok(())
    }

    /// Insert a media item and atomically assign the next position in a single query.
    /// This avoids race conditions from separate SELECT MAX + INSERT operations.
    pub async fn get_next_position(&self, playlist_id: &PlaylistId) -> Result<i32> {
        let next_pos: i32 = sqlx::query_scalar(
            r"
            SELECT COALESCE(MAX(position), -1) + 1
            FROM media
            WHERE playlist_id = $1 AND deleted_at IS NULL
            FOR UPDATE
            "
        )
        .bind(playlist_id.as_str())
        .fetch_one(&self.pool)
        .await?;

        Ok(next_pos)
    }

    /// Count media items in a playlist
    pub async fn count_by_playlist(&self, playlist_id: &PlaylistId) -> Result<i64> {
        let count: i64 = sqlx::query_scalar(
            r"
            SELECT COUNT(*) FROM media WHERE playlist_id = $1 AND deleted_at IS NULL
            "
        )
        .bind(playlist_id.as_str())
        .fetch_one(&self.pool)
        .await?;

        Ok(count)
    }

    /// Batch count media items across multiple playlists
    pub async fn count_by_playlists_batch(&self, playlist_ids: &[&str]) -> Result<std::collections::HashMap<String, i64>> {
        use sqlx::Row;
        let rows = sqlx::query(
            r"
            SELECT playlist_id, COUNT(*) as cnt
            FROM media
            WHERE playlist_id = ANY($1) AND deleted_at IS NULL
            GROUP BY playlist_id
            "
        )
        .bind(playlist_ids)
        .fetch_all(&self.pool)
        .await?;

        let mut result = std::collections::HashMap::new();
        for row in rows {
            let pid: String = row.try_get("playlist_id")?;
            let cnt: i64 = row.try_get("cnt")?;
            result.insert(pid, cnt);
        }
        Ok(result)
    }

    /// Convert database row to Media
    fn row_to_media(&self, row: PgRow) -> Result<Media> {
        Ok(Media {
            id: MediaId::from_string(row.try_get("id")?),
            playlist_id: PlaylistId::from_string(row.try_get("playlist_id")?),
            room_id: RoomId::from_string(row.try_get("room_id")?),
            creator_id: crate::models::UserId::from_string(row.try_get("creator_id")?),
            name: row.try_get("name")?,
            position: row.try_get("position")?,
            source_provider: row.try_get("source_provider")?,
            source_config: row.try_get("source_config")?,
            provider_instance_name: row.try_get("provider_instance_name")?,
            added_at: row.try_get("added_at")?,
            deleted_at: row.try_get("deleted_at")?,
        })
    }
}

#[cfg(test)]
mod tests {

    #[tokio::test]
    #[ignore = "Requires database"]
    async fn test_create_media() {
        // Integration test placeholder
    }
}
