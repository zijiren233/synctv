//! Playback state management service
//!
//! Handles playback coordination including play/pause, seeking, speed changes,
//! and media switching with optimistic locking for concurrent updates.

use std::sync::Arc;
use std::time::Duration;

use crate::{
    cache::{CacheInvalidationService, InvalidationMessage},
    models::{RoomId, UserId, MediaId, PlaylistId, PermissionBits, RoomPlaybackState, RoomSettings, PlayMode},
    repository::{RoomPlaybackStateRepository, MediaRepository},
    service::{permission::PermissionService, media::MediaService, notification::NotificationService},
    Error, Result,
};
use rand::prelude::IteratorRandom;
use rand::RngExt;

/// Trait for broadcasting playback state changes to cluster replicas.
///
/// This abstracts over the cluster manager so that `synctv-core` does not
/// depend on `synctv-cluster`.  The implementation lives in the API/wiring
/// layer where `ClusterManager` is available.
pub trait PlaybackBroadcaster: Send + Sync {
    /// Broadcast a playback state change to other cluster replicas.
    /// Implementations should be non-blocking (fire-and-forget).
    fn broadcast_playback_state(&self, state: &RoomPlaybackState);
}

/// Playback management service
///
/// Responsible for playback state coordination and optimistic locking.
#[derive(Clone)]
pub struct PlaybackService {
    playback_repo: RoomPlaybackStateRepository,
    permission_service: PermissionService,
    media_service: MediaService,
    media_repo: MediaRepository,
    /// Optional notification service for broadcasting to local WebSocket clients
    notification_service: Option<NotificationService>,
    /// Optional cluster broadcaster for cross-replica sync
    cluster_broadcaster: Option<Arc<dyn PlaybackBroadcaster>>,
    /// L1 in-memory cache for playback state, keyed by room_id
    playback_cache: Arc<moka::future::Cache<String, RoomPlaybackState>>,
    /// Optional cache invalidation service for cross-replica cache sync
    invalidation_service: Option<Arc<CacheInvalidationService>>,
}

impl std::fmt::Debug for PlaybackService {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("PlaybackService").finish()
    }
}

impl PlaybackService {
    /// Default playback state cache capacity (max entries)
    pub const DEFAULT_CACHE_SIZE: u64 = 5_000;
    /// Default playback state cache TTL in seconds (short — playback changes frequently)
    pub const DEFAULT_CACHE_TTL_SECS: u64 = 5;

    /// Create a new playback service
    #[must_use]
    pub fn new(
        playback_repo: RoomPlaybackStateRepository,
        permission_service: PermissionService,
        media_service: MediaService,
        media_repo: MediaRepository,
    ) -> Self {
        Self {
            playback_repo,
            permission_service,
            media_service,
            media_repo,
            notification_service: None,
            cluster_broadcaster: None,
            playback_cache: Arc::new(
                moka::future::CacheBuilder::new(Self::DEFAULT_CACHE_SIZE)
                    .time_to_live(Duration::from_secs(Self::DEFAULT_CACHE_TTL_SECS))
                    .build(),
            ),
            invalidation_service: None,
        }
    }

    /// Set the notification service for broadcasting playback state to local WebSocket clients
    pub fn set_notification_service(&mut self, service: NotificationService) {
        self.notification_service = Some(service);
    }

    /// Set the cluster broadcaster for cross-replica playback state sync
    pub fn set_cluster_broadcaster(&mut self, broadcaster: Arc<dyn PlaybackBroadcaster>) {
        self.cluster_broadcaster = Some(broadcaster);
    }

    /// Set the cache invalidation service and start listening for cross-replica invalidation.
    ///
    /// When another replica updates playback state and broadcasts an invalidation
    /// message, this node's local L1 cache entry for that room is evicted so the
    /// next read fetches fresh data from the DB.
    pub fn set_invalidation_service(&mut self, service: Arc<CacheInvalidationService>) {
        let cache = self.playback_cache.clone();
        let mut receiver = service.subscribe();

        tokio::spawn(async move {
            loop {
                match receiver.recv().await {
                    Ok(msg) => match msg {
                        InvalidationMessage::PlaybackState { room_id } => {
                            cache.invalidate(&room_id).await;
                            tracing::debug!(
                                room_id = %room_id,
                                "Playback state cache invalidated (cross-replica)"
                            );
                        }
                        InvalidationMessage::Room { room_id } => {
                            // Room-scoped invalidation also clears playback cache
                            cache.invalidate(&room_id).await;
                        }
                        InvalidationMessage::All => {
                            cache.invalidate_all();
                            tracing::debug!("All playback state cache invalidated (cross-replica)");
                        }
                        _ => {
                            // Other message types not relevant to playback cache
                        }
                    },
                    Err(tokio::sync::broadcast::error::RecvError::Closed) => {
                        tracing::debug!("Playback cache invalidation channel closed, stopping listener");
                        break;
                    }
                    Err(tokio::sync::broadcast::error::RecvError::Lagged(n)) => {
                        tracing::warn!(
                            lagged_messages = n,
                            "Playback cache invalidation listener lagged, flushing all entries"
                        );
                        cache.invalidate_all();
                    }
                }
            }
        });

        self.invalidation_service = Some(service);
    }

    /// Broadcast a playback state change to local clients and cluster replicas.
    ///
    /// Best-effort: logs warnings on failure but does not propagate errors,
    /// since broadcasting is not critical to the mutation itself.
    async fn broadcast_state_change(&self, state: &RoomPlaybackState) {
        // 1. Notify local WebSocket clients
        if let Some(ref ns) = self.notification_service {
            if let Err(e) = ns.notify_playback_state_changed(
                &state.room_id,
                state.is_playing,
                state.current_time as i64,
                state.speed,
                state.playing_media_id.as_ref().map(|id| id.as_str().to_string()),
            ).await {
                tracing::warn!(
                    error = %e,
                    room_id = %state.room_id.as_str(),
                    "Failed to notify local clients of playback state change"
                );
            }
        }

        // 2. Broadcast to other cluster replicas
        if let Some(ref broadcaster) = self.cluster_broadcaster {
            broadcaster.broadcast_playback_state(state);
        }
    }

    /// Get playback state for a room.
    ///
    /// Checks the L1 in-memory cache first; on miss, falls through to the
    /// database and populates the cache for subsequent reads.
    pub async fn get_state(&self, room_id: &RoomId) -> Result<RoomPlaybackState> {
        let cache_key = room_id.as_str().to_string();

        // L1 cache hit
        if let Some(state) = self.playback_cache.get(&cache_key).await {
            return Ok(state);
        }

        // Cache miss — fetch from DB (pure read, no INSERT)
        let state = match self.playback_repo.get(room_id).await? {
            Some(s) => s,
            None => RoomPlaybackState::new(room_id.clone()),
        };

        // Populate cache
        self.playback_cache.insert(cache_key, state.clone()).await;

        Ok(state)
    }

    /// Invalidate the local playback state cache for a room.
    ///
    /// If a `CacheInvalidationService` is configured, this also broadcasts the
    /// invalidation to other replicas via Redis Pub/Sub.
    pub async fn invalidate_playback_cache(&self, room_id: &RoomId) {
        // Broadcast to other replicas first (if configured)
        if let Some(ref service) = self.invalidation_service {
            if let Err(e) = service.invalidate_playback_state(room_id).await {
                tracing::warn!(
                    error = %e,
                    room_id = %room_id.as_str(),
                    "Failed to broadcast playback state cache invalidation"
                );
            }
        }

        // Invalidate local cache
        let cache_key = room_id.as_str().to_string();
        self.playback_cache.invalidate(&cache_key).await;
    }

    /// Play/pause playback
    pub async fn set_playing(
        &self,
        room_id: RoomId,
        user_id: UserId,
        playing: bool,
    ) -> Result<RoomPlaybackState> {
        self.permission_service
            .check_permission(&room_id, &user_id, PermissionBits::PLAY_PAUSE)
            .await?;

        let state = self.update_state(room_id, |state| {
            state.is_playing = playing;
            state.updated_at = chrono::Utc::now();
            // version is incremented by the SQL UPDATE, not here
        })
        .await?;

        self.broadcast_state_change(&state).await;
        Ok(state)
    }

    /// Seek to position
    pub async fn seek(
        &self,
        room_id: RoomId,
        user_id: UserId,
        current_time: f64,
    ) -> Result<RoomPlaybackState> {
        if current_time < 0.0 {
            return Err(Error::InvalidInput("Seek position must be non-negative".to_string()));
        }

        self.permission_service
            .check_permission(&room_id, &user_id, PermissionBits::SEEK)
            .await?;

        let state = self.update_state(room_id, |state| {
            state.current_time = current_time;
            state.updated_at = chrono::Utc::now();
            // version is incremented by the SQL UPDATE, not here
        })
        .await?;

        self.broadcast_state_change(&state).await;
        Ok(state)
    }

    /// Change playback speed
    pub async fn change_speed(
        &self,
        room_id: RoomId,
        user_id: UserId,
        speed: f64,
    ) -> Result<RoomPlaybackState> {
        self.permission_service
            .check_permission(&room_id, &user_id, PermissionBits::CHANGE_SPEED)
            .await?;

        // Validate speed range
        if !(0.25..=4.0).contains(&speed) {
            return Err(Error::InvalidInput("Speed must be between 0.25 and 4.0".to_string()));
        }

        let state = self.update_state(room_id, |state| {
            state.speed = speed;
            state.updated_at = chrono::Utc::now();
            // version is incremented by the SQL UPDATE, not here
        })
        .await?;

        self.broadcast_state_change(&state).await;
        Ok(state)
    }

    /// Switch to different media in playlist
    pub async fn switch_media(
        &self,
        room_id: RoomId,
        user_id: UserId,
        media_id: MediaId,
    ) -> Result<RoomPlaybackState> {
        self.switch_media_with_context(room_id, user_id, media_id, None, String::new()).await
    }

    /// Switch to different media with playlist context and media path
    pub async fn switch_media_with_context(
        &self,
        room_id: RoomId,
        user_id: UserId,
        media_id: MediaId,
        playlist_id: Option<PlaylistId>,
        media_path: String,
    ) -> Result<RoomPlaybackState> {
        self.permission_service
            .check_permission(&room_id, &user_id, PermissionBits::SWITCH_MEDIA)
            .await?;

        // Verify media exists in this room
        let media = self
            .media_service
            .get_media(&media_id)
            .await?
            .ok_or_else(|| Error::NotFound("Media not found".to_string()))?;

        if media.room_id != room_id {
            return Err(Error::Authorization("Media does not belong to this room".to_string()));
        }

        let state = self.update_state(room_id, |state| {
            state.playing_media_id = Some(media_id.clone());
            state.playing_playlist_id = playlist_id.clone();
            state.relative_path = media_path.clone();
            state.current_time = 0.0;
            state.is_playing = true;
            state.updated_at = chrono::Utc::now();
            // version is incremented by the SQL UPDATE, not here
        })
        .await?;

        self.broadcast_state_change(&state).await;
        Ok(state)
    }

    /// Play next media in playlist (auto-play next episode)
    ///
    /// This is called when current media finishes playing.
    /// Returns the new playback state if successful, or None if there's no next media.
    pub async fn play_next(
        &self,
        room_id: &RoomId,
        settings: &RoomSettings,
    ) -> Result<Option<RoomPlaybackState>> {
        // Use new auto_play settings, falling back to legacy fields for compatibility
        let (enabled, mode) = if settings.auto_play.value.enabled || settings.auto_play_next.0 {
            let mode = settings.auto_play.value.mode;
            let enabled = settings.auto_play.value.enabled || settings.auto_play_next.0;

            // If legacy fields suggest a different mode than the new setting, use legacy
            let mode = if settings.loop_playlist.0 {
                PlayMode::RepeatAll
            } else if settings.shuffle_playlist.0 {
                PlayMode::Shuffle
            } else {
                mode
            };

            (enabled, mode)
        } else {
            (false, PlayMode::Sequential)
        };

        if !enabled {
            return Ok(None);
        }

        // Get current state
        let state = self.get_state(room_id).await?;

        // Get playlist
        let playlist = self.media_repo.get_playlist(room_id).await?;

        if playlist.is_empty() {
            return Ok(None);
        }

        // Handle different play modes
        let next_media = match mode {
            PlayMode::Sequential => {
                // Find next media by position
                let current_pos = if let Some(ref current_id) = state.playing_media_id {
                    playlist.iter()
                        .position(|m| &m.id == current_id)
                        .unwrap_or(0)
                } else {
                    0
                };

                if current_pos + 1 < playlist.len() {
                    Some(&playlist[current_pos + 1])
                } else {
                    None // End of playlist
                }
            }

            PlayMode::RepeatOne => {
                // Repeat current media
                if let Some(ref current_id) = state.playing_media_id {
                    playlist.iter()
                        .find(|m| &m.id == current_id)
                } else {
                    playlist.first()
                }
            }

            PlayMode::RepeatAll => {
                // Loop back to start
                let current_pos = if let Some(ref current_id) = state.playing_media_id {
                    playlist.iter()
                        .position(|m| &m.id == current_id)
                        .unwrap_or(0)
                } else {
                    0
                };

                let next_pos = (current_pos + 1) % playlist.len();
                Some(&playlist[next_pos])
            }

            PlayMode::Shuffle => {
                // Random next media (excluding current)
                //
                // NOTE: This is a simplified shuffle implementation that randomly selects
                // the next media from the playlist (excluding the current one).
                //
                // Pros: Simple, efficient, no additional state storage required
                // Cons: May play some media more frequently than others
                //
                // For a production-grade shuffle without repeats, consider implementing
                // Fisher-Yates shuffle algorithm with persistent state storage (Redis):
                // 1. Shuffle the entire playlist once
                // 2. Play through shuffled order
                // 3. Re-shuffle when all items played
                // See: /Volumes/workspace/rust/design/13-自动连播设计.md §3.4
                if let Some(ref current_id) = state.playing_media_id {
                    playlist.iter()
                        .filter(|m| &m.id != current_id)
                        .choose(&mut rand::rng())
                } else {
                    playlist.first()
                }
            }
        };

        // Switch to next media
        if let Some(next) = next_media {
            let new_state = self.update_state(room_id.clone(), |state| {
                state.playing_media_id = Some(next.id.clone());
                state.current_time = 0.0;
                state.is_playing = true;
                state.updated_at = chrono::Utc::now();
                // version is incremented by the SQL UPDATE, not here
            }).await?;

            tracing::info!(
                room_id = %room_id.as_str(),
                media_id = %next.id.as_str(),
                name = %next.name,
                mode = ?mode,
                "Auto-played next media"
            );

            self.broadcast_state_change(&new_state).await;
            Ok(Some(new_state))
        } else {
            tracing::info!(
                room_id = %room_id.as_str(),
                mode = ?mode,
                "Playlist ended"
            );
            Ok(None)
        }
    }

    /// Check if media has ended and auto-play next if needed
    ///
    /// This should be called when playback `current_time` is updated.
    /// It checks if the current time has reached or exceeded the media duration.
    pub async fn check_and_auto_play(
        &self,
        room_id: &RoomId,
        settings: &RoomSettings,
        current_time: f64,
    ) -> Result<Option<RoomPlaybackState>> {
        // Use new auto_play settings with legacy fallback
        let enabled = settings.auto_play.value.enabled || settings.auto_play_next.0;

        if !enabled {
            return Ok(None);
        }

        // Get current media to check duration
        let state = self.get_state(room_id).await?;
        let playing_media_id = state.playing_media_id;

        let playing_media = match playing_media_id {
            Some(ref id) => self.media_service.get_media(id).await?.ok_or_else(|| {
                Error::NotFound("Current media not found".to_string())
            })?,
            None => return Ok(None),
        };

        // Check if media has metadata with duration
        // For direct URLs, get duration from PlaybackResult metadata
        // For provider-based media, duration check is skipped (client should handle)
        let duration = if playing_media.is_direct() {
            if let Some(playback_result) = playing_media.get_playback_result() {
                playback_result.metadata.get("duration")
                    .and_then(serde_json::Value::as_f64)
            } else {
                return Ok(None);
            }
        } else {
            // For provider-based media, auto-play is handled by client or provider
            return Ok(None);
        };

        // Check if current_time is near end (within 1 second or past end)
        if let Some(dur) = duration {
            if current_time >= dur - 1.0 {
                // Auto-play next media
                self.play_next(room_id, settings).await
            } else {
                Ok(None)
            }
        } else {
            Ok(None)
        }
    }

    /// Maximum retry attempts for optimistic lock conflicts
    const MAX_RETRIES: u32 = 3;
    /// Base delay for exponential backoff (milliseconds)
    const BACKOFF_BASE_MS: u64 = 5;

    /// Update playback state with generic update function.
    ///
    /// Uses optimistic locking with automatic retry on version conflicts.
    /// Retries use exponential backoff with jitter to avoid thundering herd.
    pub async fn update_state<F>(
        &self,
        room_id: RoomId,
        update_fn: F,
    ) -> Result<RoomPlaybackState>
    where
        F: Fn(&mut RoomPlaybackState),
    {
        for attempt in 0..Self::MAX_RETRIES {
            // Get current state (lazy-init: only INSERT if row doesn't exist yet)
            let mut state = match self.playback_repo.get(&room_id).await? {
                Some(s) => s,
                None => self.playback_repo.create_or_get(&room_id).await?,
            };

            // Apply update
            update_fn(&mut state);

            // Save with optimistic locking
            match self.playback_repo.update(&state).await {
                Ok(updated_state) => {
                    // Invalidate local cache so the next read fetches fresh data.
                    // This avoids write-through which would self-invalidate when the
                    // Redis Pub/Sub bounce-back arrives.
                    let cache_key = room_id.as_str().to_string();
                    self.playback_cache.invalidate(&cache_key).await;

                    // Broadcast invalidation to other replicas so they evict stale entries
                    if let Some(ref service) = self.invalidation_service {
                        if let Err(e) = service.invalidate_playback_state(&room_id).await {
                            tracing::warn!(
                                error = %e,
                                room_id = %room_id.as_str(),
                                "Failed to broadcast playback state cache invalidation after update"
                            );
                        }
                    }

                    return Ok(updated_state);
                }
                Err(Error::OptimisticLockConflict) if attempt + 1 < Self::MAX_RETRIES => {
                    // Exponential backoff with jitter: base * 2^attempt + random(0..base)
                    let backoff = Self::BACKOFF_BASE_MS * (1 << attempt);
                    let jitter = rand::rng().random_range(0..Self::BACKOFF_BASE_MS);
                    let delay = backoff + jitter;
                    tracing::debug!(
                        room_id = %room_id.as_str(),
                        attempt = attempt + 1,
                        delay_ms = delay,
                        "Playback state version conflict, retrying with backoff"
                    );
                    tokio::time::sleep(std::time::Duration::from_millis(delay)).await;
                    continue;
                }
                Err(e) => return Err(e),
            }
        }

        Err(Error::Internal(
            "Playback state update failed after maximum retry attempts".to_string(),
        ))
    }

    /// Reset playback to initial state
    pub async fn reset(&self, room_id: RoomId, user_id: UserId) -> Result<RoomPlaybackState> {
        self.permission_service
            .check_permission(&room_id, &user_id, PermissionBits::PLAY_PAUSE)
            .await?;

        let state = self.update_state(room_id, |state| {
            state.is_playing = false;
            state.current_time = 0.0;
            state.speed = 1.0;
            state.playing_media_id = None;
            state.playing_playlist_id = None;
            state.relative_path = String::new();
            state.updated_at = chrono::Utc::now();
            // version is incremented by the SQL UPDATE, not here
        })
        .await?;

        self.broadcast_state_change(&state).await;
        Ok(state)
    }

    /// Check if playback is currently active
    pub async fn is_playing(&self, room_id: &RoomId) -> Result<bool> {
        let state = self.get_state(room_id).await?;
        Ok(state.is_playing)
    }

    /// Get current media being played
    pub async fn get_playing_media_id(&self, room_id: &RoomId) -> Result<Option<MediaId>> {
        let state = self.get_state(room_id).await?;
        Ok(state.playing_media_id)
    }

    /// Get current playback position
    pub async fn get_current_time(&self, room_id: &RoomId) -> Result<f64> {
        let state = self.get_state(room_id).await?;
        Ok(state.current_time)
    }

    /// Get current playback speed
    pub async fn get_speed(&self, room_id: &RoomId) -> Result<f64> {
        let state = self.get_state(room_id).await?;
        Ok(state.speed)
    }

    /// Update multiple playback properties at once
    pub async fn update_multiple(
        &self,
        room_id: RoomId,
        user_id: UserId,
        playing: Option<bool>,
        current_time: Option<f64>,
        speed: Option<f64>,
        media_id: Option<MediaId>,
    ) -> Result<RoomPlaybackState> {
        // Check permissions based on what's being updated
        let mut required_perms = PermissionBits::NONE;
        if playing.is_some() {
            required_perms |= PermissionBits::PLAY_PAUSE;
        }
        if current_time.is_some() {
            required_perms |= PermissionBits::SEEK;
        }
        if speed.is_some() {
            required_perms |= PermissionBits::CHANGE_SPEED;
        }
        if media_id.is_some() {
            required_perms |= PermissionBits::SWITCH_MEDIA;
        }

        if required_perms != PermissionBits::NONE {
            self.permission_service
                .check_permission(&room_id, &user_id, required_perms)
                .await?;
        }

        // Validate speed range if provided
        if let Some(s) = speed {
            if !(0.25..=4.0).contains(&s) {
                return Err(Error::InvalidInput("Speed must be between 0.25 and 4.0".to_string()));
            }
        }

        // If media_id is provided, verify it exists
        if let Some(ref mid) = media_id {
            let media = self
                .media_service
                .get_media(mid)
                .await?
                .ok_or_else(|| Error::NotFound("Media not found".to_string()))?;

            if media.room_id != room_id {
                return Err(Error::Authorization("Media does not belong to this room".to_string()));
            }
        }

        let state = self.update_state(room_id, |state| {
            if let Some(p) = playing {
                state.is_playing = p;
            }
            if let Some(ct) = current_time {
                state.current_time = ct;
            }
            if let Some(s) = speed {
                state.speed = s;
            }
            if let Some(ref mid) = media_id {
                state.playing_media_id = Some(mid.clone());
            }
            state.updated_at = chrono::Utc::now();
            // version is incremented by the SQL UPDATE, not here
        })
        .await?;

        self.broadcast_state_change(&state).await;
        Ok(state)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    #[ignore = "Requires database"]
    async fn test_play_pause() {
        // Integration test placeholder
    }

    #[tokio::test]
    #[ignore = "Requires database"]
    async fn test_seek() {
        // Integration test placeholder
    }

    #[test]
    fn test_speed_validation_bounds() {
        // Valid boundary values
        assert!((0.25..=4.0).contains(&0.25));
        assert!((0.25..=4.0).contains(&4.0));
        assert!((0.25..=4.0).contains(&1.0));

        // Invalid boundary values
        assert!(!(0.25..=4.0).contains(&0.24));
        assert!(!(0.25..=4.0).contains(&4.1));
        assert!(!(0.25..=4.0).contains(&0.0));
        assert!(!(0.25..=4.0).contains(&-1.0));
    }

    #[test]
    fn test_seek_negative_position() {
        let position = -1.0_f64;
        assert!(position < 0.0, "Negative seek positions should be rejected");

        let position = 0.0_f64;
        assert!(!(position < 0.0), "Zero seek position should be accepted");

        let position = 42.5_f64;
        assert!(!(position < 0.0), "Positive seek position should be accepted");
    }

    #[test]
    fn test_update_state_constants() {
        assert_eq!(PlaybackService::MAX_RETRIES, 3);
        assert_eq!(PlaybackService::BACKOFF_BASE_MS, 5);
    }
}
