//! Kubernetes DNS-based cluster node discovery
//!
//! Discovers cluster peers by resolving A records from a Kubernetes headless service.
//! Pattern: `{service-name}.{namespace}.svc.cluster.local`
//!
//! Each resolved IP corresponds to a pod backing the headless service.
//! Combined with a known gRPC/HTTP port, this yields routable peer addresses
//! without requiring Redis for discovery.

use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use tokio::time::{interval, Duration};
use tokio_util::sync::CancellationToken;

use super::node_registry::NodeInfo;
use crate::error::{Error, Result};

/// Discovered peer from DNS resolution
#[derive(Debug, Clone)]
pub struct DnsPeer {
    /// IP address resolved from DNS
    pub ip: String,
    /// gRPC address (ip:grpc_port)
    pub grpc_address: String,
    /// HTTP address (ip:http_port)
    pub http_address: String,
}

/// Kubernetes DNS-based discovery for cluster peers.
///
/// Resolves the headless service DNS name to discover peer pod IPs,
/// then constructs gRPC/HTTP addresses using configured ports.
pub struct K8sDnsDiscovery {
    /// Headless service DNS name (e.g., "synctv-headless.default.svc.cluster.local")
    dns_name: String,
    /// gRPC port used by all peers
    grpc_port: u16,
    /// HTTP port used by all peers
    http_port: u16,
    /// This node's pod IP (to exclude self from peer list)
    self_ip: String,
    /// Cached list of discovered peers
    peers: Arc<RwLock<Vec<DnsPeer>>>,
    /// Cancellation token for the background refresh loop
    cancel_token: CancellationToken,
}

impl K8sDnsDiscovery {
    /// Create a new K8s DNS discovery instance from environment variables.
    ///
    /// Required env vars:
    /// - `HEADLESS_SERVICE_NAME`: name of the K8s headless service
    /// - `POD_NAMESPACE`: namespace of the pod (from downward API)
    /// - `POD_IP`: this pod's IP address (from downward API)
    ///
    /// Ports are read from config (grpc_port, http_port).
    pub fn from_env(grpc_port: u16, http_port: u16) -> Result<Self> {
        let service_name = std::env::var("HEADLESS_SERVICE_NAME").map_err(|_| {
            Error::Configuration(
                "HEADLESS_SERVICE_NAME env var is required for k8s_dns discovery mode".to_string(),
            )
        })?;

        let namespace = std::env::var("POD_NAMESPACE").map_err(|_| {
            Error::Configuration(
                "POD_NAMESPACE env var is required for k8s_dns discovery mode".to_string(),
            )
        })?;

        let self_ip = std::env::var("POD_IP").unwrap_or_default();

        let dns_name = format!("{service_name}.{namespace}.svc.cluster.local");

        Ok(Self {
            dns_name,
            grpc_port,
            http_port,
            self_ip,
            peers: Arc::new(RwLock::new(Vec::new())),
            cancel_token: CancellationToken::new(),
        })
    }

    /// Create with explicit parameters (for testing or non-standard setups).
    pub fn new(
        dns_name: String,
        grpc_port: u16,
        http_port: u16,
        self_ip: String,
    ) -> Self {
        Self {
            dns_name,
            grpc_port,
            http_port,
            self_ip,
            peers: Arc::new(RwLock::new(Vec::new())),
            cancel_token: CancellationToken::new(),
        }
    }

    /// Perform a single DNS resolution and return discovered peers.
    pub async fn resolve_once(&self) -> Result<Vec<DnsPeer>> {
        let lookup_addr = format!("{}:{}", self.dns_name, self.grpc_port);

        let addrs = tokio::net::lookup_host(&lookup_addr)
            .await
            .map_err(|e| {
                Error::Configuration(format!(
                    "DNS lookup failed for '{}': {}",
                    self.dns_name, e
                ))
            })?;

        let mut peers = Vec::new();
        let mut seen_ips = std::collections::HashSet::new();

        for addr in addrs {
            let ip = addr.ip().to_string();

            // Skip self
            if ip == self.self_ip {
                continue;
            }

            // Deduplicate (DNS may return same IP multiple times)
            if !seen_ips.insert(ip.clone()) {
                continue;
            }

            peers.push(DnsPeer {
                ip: ip.clone(),
                grpc_address: format!("{}:{}", ip, self.grpc_port),
                http_address: format!("{}:{}", ip, self.http_port),
            });
        }

        Ok(peers)
    }

    /// Resolve peers and update the internal cache.
    pub async fn refresh(&self) -> Result<()> {
        match self.resolve_once().await {
            Ok(new_peers) => {
                let count = new_peers.len();
                let mut cached = self.peers.write().await;
                *cached = new_peers;
                tracing::debug!(
                    dns_name = %self.dns_name,
                    peer_count = count,
                    "K8s DNS discovery refreshed"
                );
                Ok(())
            }
            Err(e) => {
                tracing::warn!(
                    dns_name = %self.dns_name,
                    error = %e,
                    "K8s DNS discovery refresh failed, keeping cached peers"
                );
                Err(e)
            }
        }
    }

    /// Get the current cached list of discovered peers.
    pub async fn get_peers(&self) -> Vec<DnsPeer> {
        self.peers.read().await.clone()
    }

    /// Convert discovered peers to `NodeInfo` structs for compatibility
    /// with the existing cluster infrastructure (health monitor, load balancer).
    pub async fn get_peers_as_node_info(&self) -> Vec<NodeInfo> {
        let peers = self.peers.read().await;
        peers
            .iter()
            .map(|peer| {
                let mut info = NodeInfo::new(
                    peer.ip.clone(),
                    peer.grpc_address.clone(),
                    peer.http_address.clone(),
                );
                info.metadata
                    .insert("discovery".to_string(), "k8s_dns".to_string());
                info
            })
            .collect()
    }

    /// Start a background loop that periodically re-resolves DNS to track
    /// scaling events (pod additions/removals).
    ///
    /// Returns the `JoinHandle` for the background task.
    pub async fn start_refresh_loop(
        &self,
        interval_secs: u64,
    ) -> tokio::task::JoinHandle<()> {
        let dns_name = self.dns_name.clone();
        let grpc_port = self.grpc_port;
        let http_port = self.http_port;
        let self_ip = self.self_ip.clone();
        let peers = self.peers.clone();
        let cancel_token = self.cancel_token.clone();

        tokio::spawn(async move {
            let mut timer = interval(Duration::from_secs(interval_secs));

            loop {
                tokio::select! {
                    () = cancel_token.cancelled() => {
                        tracing::info!("K8s DNS discovery refresh loop shutting down");
                        return;
                    }
                    _ = timer.tick() => {
                        let lookup_addr = format!("{}:{}", dns_name, grpc_port);
                        let result = tokio::net::lookup_host(&lookup_addr).await;
                        match result {
                            Ok(addrs) => {
                                let mut new_peers = Vec::new();
                                let mut seen_ips = std::collections::HashSet::new();

                                for addr in addrs {
                                    let ip = addr.ip().to_string();
                                    if ip == self_ip {
                                        continue;
                                    }
                                    if !seen_ips.insert(ip.clone()) {
                                        continue;
                                    }
                                    new_peers.push(DnsPeer {
                                        ip: ip.clone(),
                                        grpc_address: format!("{}:{}", ip, grpc_port),
                                        http_address: format!("{}:{}", ip, http_port),
                                    });
                                }

                                let count = new_peers.len();
                                let mut cached = peers.write().await;
                                *cached = new_peers;
                                tracing::debug!(
                                    peer_count = count,
                                    "K8s DNS discovery refreshed"
                                );
                            }
                            Err(e) => {
                                tracing::warn!(
                                    error = %e,
                                    "K8s DNS refresh failed, keeping cached peers"
                                );
                            }
                        }
                    }
                }
            }
        })
    }

    /// Gracefully shut down the background refresh loop.
    pub async fn shutdown(&self) {
        self.cancel_token.cancel();
    }

    /// Get the DNS name being resolved.
    #[must_use]
    pub fn dns_name(&self) -> &str {
        &self.dns_name
    }

    /// Build a `HashMap<String, NodeInfo>` keyed by node_id (IP) for
    /// compatibility with code that needs to look up peers by ID.
    pub async fn get_peer_map(&self) -> HashMap<String, NodeInfo> {
        let peers = self.get_peers_as_node_info().await;
        peers
            .into_iter()
            .map(|info| (info.node_id.clone(), info))
            .collect()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_k8s_dns_discovery_new() {
        let disc = K8sDnsDiscovery::new(
            "synctv-headless.default.svc.cluster.local".to_string(),
            50051,
            8080,
            "10.0.0.1".to_string(),
        );
        assert_eq!(disc.dns_name(), "synctv-headless.default.svc.cluster.local");
        assert_eq!(disc.grpc_port, 50051);
        assert_eq!(disc.http_port, 8080);
        assert_eq!(disc.self_ip, "10.0.0.1");
    }

    #[tokio::test]
    async fn test_get_peers_empty_initially() {
        let disc = K8sDnsDiscovery::new(
            "test.default.svc.cluster.local".to_string(),
            50051,
            8080,
            "10.0.0.1".to_string(),
        );
        let peers = disc.get_peers().await;
        assert!(peers.is_empty());
    }

    #[tokio::test]
    async fn test_get_peers_as_node_info_empty() {
        let disc = K8sDnsDiscovery::new(
            "test.default.svc.cluster.local".to_string(),
            50051,
            8080,
            "10.0.0.1".to_string(),
        );
        let nodes = disc.get_peers_as_node_info().await;
        assert!(nodes.is_empty());
    }

    #[tokio::test]
    async fn test_get_peer_map_empty() {
        let disc = K8sDnsDiscovery::new(
            "test.default.svc.cluster.local".to_string(),
            50051,
            8080,
            "10.0.0.1".to_string(),
        );
        let map = disc.get_peer_map().await;
        assert!(map.is_empty());
    }
}
